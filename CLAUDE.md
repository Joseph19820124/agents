# CLAUDE.md - AI Assistant Guide for This Repository

## Project Overview

**Master AI Agentic Engineering** is a 6-week educational course teaching autonomous AI agent development across multiple frameworks. It covers OpenAI Agents SDK, CrewAI, LangGraph, AutoGen, and Model Context Protocol (MCP). The repository contains lab notebooks, production-style applications, and community contributions.

- **Author:** Ed Donner
- **License:** MIT
- **Python:** >= 3.12 (specified in `pyproject.toml` and `.python-version`)
- **Package Manager:** `uv` (with `uv.lock` for reproducibility)

## Repository Structure

```
agents/
├── 1_foundations/          # Week 1: Core AI agent concepts, tool use, ReAct patterns
├── 2_openai/              # Week 2: OpenAI Agents SDK, deep research app
├── 3_crew/                # Week 3: CrewAI framework, multi-agent coordination
├── 4_langgraph/           # Week 4: LangGraph workflows, stateful agents
├── 5_autogen/             # Week 5: AutoGen framework, distributed agents
├── 6_mcp/                 # Week 6: Model Context Protocol, stock trading app
├── guides/                # 12 educational notebooks (Python, async, APIs, etc.)
├── setup/                 # Platform-specific setup guides (Mac, PC, Linux, WSL)
├── assets/                # Images for README and course materials
├── pyproject.toml         # Project metadata and 41 direct dependencies
├── requirements.txt       # Full resolved dependency list (~690 packages)
├── uv.lock                # UV lock file for reproducible installs
├── .python-version        # Python 3.12
├── README.md              # Main documentation (English)
├── README_zh.md           # Chinese translation
└── COMMIT_HISTORY_ANALYSIS.md  # Git history analysis report
```

### Module Details

Each weekly module (`1_foundations/` through `6_mcp/`) follows a consistent layout:
- **Numbered lab notebooks:** `1_lab1.ipynb`, `2_lab2.ipynb`, etc.
- **Application code:** `app.py` and supporting modules
- **Community contributions:** `community_contributions/` subdirectory with alternative implementations

### Key Applications

| Module | App | Description |
|--------|-----|-------------|
| `1_foundations/` | `app.py` | "Me" chatbot with tool use |
| `2_openai/deep_research/` | `deep_research.py` | Gradio-based research agent with planner, search, writer, email agents |
| `3_crew/` | Multiple crew projects | `coder/`, `debate/`, `engineering_team/`, `financial_researcher/`, `stock_picker/` |
| `4_langgraph/` | `app.py` | Sidekick personal co-worker assistant |
| `5_autogen/` | `agent.py`, `world.py` | RoutedAgent with message passing |
| `6_mcp/` | `app.py` | Multi-agent stock trading simulation with Polygon API |

## Build and Run Commands

### Environment Setup

```bash
# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install all dependencies
uv sync

# Install CrewAI tool (required for Week 3)
uv tool install crewai
# Or upgrade if already installed:
uv tool upgrade crewai
```

### Running Applications

```bash
# Run Gradio-based apps (Weeks 1, 2, 4, 6)
uv run python <module>/app.py

# Run Jupyter notebooks
uv run jupyter lab

# Run CrewAI projects (Week 3)
cd 3_crew/<project_name>
crewai run

# Run individual Python scripts
uv run python <path/to/script.py>
```

### Environment Variables

All modules expect API keys via `.env` file in the project root (loaded with `python-dotenv`):

```
OPENAI_API_KEY=...
ANTHROPIC_API_KEY=...
GOOGLE_API_KEY=...
GEMINI_API_KEY=...        # Required for CrewAI with Gemini (same as GOOGLE_API_KEY)
POLYGON_API_KEY=...       # Week 6 stock trading
SENDGRID_API_KEY=...      # Email features in Week 2
PUSHOVER_USER_KEY=...     # Push notifications in Week 6
PUSHOVER_API_TOKEN=...
```

## Testing

There is no project-wide test suite. Testing is limited to specific community contributions:

```bash
# Tests exist primarily in community contributions
uv run pytest 3_crew/community_contributions/ghost_writer/

# Example output test files (generated by engineering_team crew)
uv run pytest 3_crew/engineering_team/example_output_4o/test_accounts.py
uv run pytest 3_crew/engineering_team/example_output_new/test_accounts.py
```

Test files use `pytest` naming convention (`test_*.py`). No CI/CD pipeline exists; this is an educational repository where students run code locally.

## Code Patterns and Conventions

### General Conventions

- **Environment loading:** Always use `load_dotenv(override=True)` at module start
- **Type hints:** Used throughout (e.g., `-> dict[str, float]`, `-> Agent`)
- **Async-first:** Heavy use of `async def` / `await` for LLM interactions
- **Imports order:** Standard library, third-party packages, local modules
- **UI framework:** Gradio (`gr.Blocks`) for all interactive applications

### Pattern 1: OpenAI Tool Use (Week 1)

```python
class Me:
    def __init__(self):
        self.openai = OpenAI()

    def chat(self, message, history):
        # Agentic loop: call model, handle tool calls, repeat
        while not done:
            response = self.openai.chat.completions.create(...)
            if response has tool_calls:
                self.handle_tool_call(tool_calls)
            else:
                done = True
```

### Pattern 2: CrewAI Decorator Pattern (Week 3)

```python
@CrewBase
class ResearchCrew():
    @agent
    def researcher(self) -> Agent:
        return Agent(config=self.agents_config['researcher'], tools=[...])

    @task
    def research_task(self) -> Task:
        return Task(config=self.tasks_config['research_task'])

    @crew
    def crew(self) -> Crew:
        return Crew(agents=self.agents, tasks=self.tasks, process=Process.sequential)
```

CrewAI projects use YAML configuration files:
- `src/<project>/config/agents.yaml` - Agent role, goal, backstory, LLM selection
- `src/<project>/config/tasks.yaml` - Task description, expected output, dependencies

### Pattern 3: Gradio UI (Weeks 1, 2, 4, 6)

```python
with gr.Blocks() as ui:
    gr.Markdown("# Title")
    with gr.Row():
        textbox = gr.Textbox(label="Input")
    button = gr.Button("Run", variant="primary")
    button.click(fn=async_handler, inputs=[textbox], outputs=[output])
ui.launch(inbrowser=True)
```

### Pattern 4: AutoGen RoutedAgent (Week 5)

```python
class Agent(RoutedAgent):
    system_message = "..."

    def __init__(self, name):
        super().__init__(name)
        self._delegate = AssistantAgent(name, model_client=client, system_message=...)

    @message_handler
    async def handle_message(self, message, ctx):
        response = await self._delegate.on_messages([...])
```

### Pattern 5: MCP Server/Client (Week 6)

- Server modules expose tools via MCP protocol (`accounts_server.py`, `market_server.py`)
- Client modules consume MCP servers (`accounts_client.py`)
- Database persistence via SQLite (`database.py`)
- Caching with `@lru_cache` for API responses

## Key Dependencies

| Category | Packages |
|----------|----------|
| **Core AI** | `openai`, `openai-agents`, `anthropic`, `langchain-openai`, `langchain-anthropic`, `langgraph`, `autogen-agentchat`, `autogen-ext`, `semantic-kernel` |
| **MCP** | `mcp[cli]`, `mcp-server-fetch`, `smithery` |
| **UI** | `gradio`, `plotly`, `ipywidgets` |
| **Data** | `requests`, `bs4`, `lxml`, `pypdf`, `pypdf2`, `polygon-api-client` |
| **Web** | `playwright`, `httpx` |
| **Utils** | `python-dotenv`, `psutil`, `wikipedia` |
| **Dev** | `ipykernel` |

## Git Conventions

- **Commit style:** Imperative mood, descriptive messages (e.g., "Add comprehensive git commit history analysis report", "Update lab1 notebook to use OpenRouter API")
- **Branch workflow:** Feature branches with pull requests; ~47% of commits are merge commits
- **Community contributions:** Submitted via PRs into `community_contributions/` subdirectories

## Files to Never Commit

These are excluded via `.gitignore` and should never be committed:

- `.env` - API keys and secrets
- `__pycache__/`, `*.pyc` - Python bytecode
- `.venv/`, `venv/` - Virtual environments
- `3_crew/engineering_team/output/` - Generated crew output
- `6_mcp/accounts.db` - Runtime database
- `6_mcp/memory/*.db` - Agent memory stores
- `.ipynb_checkpoints/` - Jupyter checkpoint files
- `build/`, `dist/`, `*.egg-info/` - Build artifacts

## Important Notes for AI Assistants

1. **This is an educational repository.** Changes should preserve the learning progression from Week 1 (foundations) through Week 6 (MCP). Do not reorganize the weekly structure.

2. **Community contributions are sacred.** The `community_contributions/` directories contain work from many students and external contributors. Avoid modifying these unless specifically asked.

3. **Multiple LLM providers are supported.** Code examples support OpenAI, Anthropic, Google/Gemini, Groq, Ollama, and OpenRouter. Do not assume a single provider.

4. **CrewAI has its own project structure.** Each crew project under `3_crew/` is a self-contained project with its own `pyproject.toml`. Use `crewai run` (not `python main.py`) to execute them.

5. **Environment variables are required.** All modules depend on API keys loaded from `.env` via `python-dotenv`. Never hardcode API keys.

6. **Notebooks are primary teaching material.** The numbered `.ipynb` files are the core course content. Maintain their sequential numbering and pedagogical flow.

7. **No CI/CD pipeline exists.** There are no automated tests or build checks. Validate changes manually by running the relevant notebooks or scripts.

8. **Windows compatibility matters.** The course supports Windows, Mac, and Linux. Be mindful of path separators and platform-specific issues (e.g., CrewAI Unicode issues on Windows noted in README).

9. **`uv` is the package manager.** Use `uv sync` to install dependencies and `uv run` to execute scripts. The `requirements.txt` is a resolved snapshot, not the source of truth for dependencies (that's `pyproject.toml`).

10. **Async patterns are pervasive.** Most LLM interaction code uses `async`/`await`. When adding new code, follow the existing async patterns.
